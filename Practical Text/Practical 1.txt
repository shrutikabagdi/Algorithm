Aim: Analyze and Demonstrate the Installation Process of Big Data Tool 
Hadoop 3.3.6 and JDK 1.8 on Windows Platform. 

THEORY: 
Hadoop software can be installed in three modes of 
Hadoop is a Java-based programming framework that supports the processing and storage of extremely large 
datasets on a cluster of inexpensive machines. It was the first major open source project in the big data playing 
field and is sponsored by the Apache Software Foundation. 
Hadoop-3.3.6 3 is comprised of four main layers: 
➢ Hadoop Common is the collection of utilities and libraries that support other Hadoop modules. 
➢ HDFS, which stands for Hadoop Distributed File System, is responsible for persisting data to disk. 
➢ YARN, short for Yet Another Resource Negotiator, is the "operating system" for HDFS. 
➢ MapReduce is the original processing model for Hadoop clusters. It distributes work within the cluster or 
map, then organizes and reduces the results from the nodes into a response to a query. Many other processing 
models are available for the 2.x version of Hadoop. 
Hadoop clusters are relatively complex to set up, so the project includes a stand-alone mode which is suitable 
for learning about Hadoop, performing simple operations, and debugging. 

Procedure: 

we'll install Hadoop in stand-alone mode and run one of the example example MapReduce programs it includes 
to verify the installation. 

Step1: Installing Java 8 version. 
Java JDK Link to download 
https://www.oracle.com/java/technologies/javase-jdk8-downloads.html 
extract and install Java in C:\Java 
– open cmd and type -> javac -version

Note: To set the path for environment variables. i.e. JAVA_HOME 
Step2: Installing Hadoop 
With Java in place, we'll visit the Apache Hadoop Releases page to find the most recent stable release. 
Follow the binary for the current release: 
Download Hadoop from www.hadoop.apache.org

1. Set the path JAVA_HOME Environment variable 
2. Set the path HADOOP_HOME Environment variable 


Configurations: - 

a) File C:/Hadoop-3.3.6/etc/hadoop/core-site.xml, paste below xml paragraph and 
save this file. 
<configuration> 
<property> 
<name>fs.defaultFS</name> 
<value>hdfs://localhost:9000</value> 
</property> 
</configuration> 

b) C:/Hadoop-3.3.6/etc/hadoop/mapred-site.xml, paste below xml paragraph and save 
this file. 
<configuration> 
<property> 
<name>mapreduce.framework.name</name> 
<value>yarn</value> 
</property> 
</configuration> 
 
c) Create folder "data" under "C:\Hadoop-3.2.1" 
1) Create folder "datanode" under "C:\Hadoop-3.2.1\data" 
2) Create folder "namenode" under "C:\Hadoop-3.2.1\data" data
 
d) Edit file C:\Hadoop-3.3.6/etc/hadoop/hdfs-site.xml, paste below xml paragraph 
and save this file. 
<configuration> 
<property> 
<name>dfs.replication</name> 
<value>1</value> 
</property> 
<property> 
<name>dfs.namenode.name.dir</name> 
<value>C:\hadoop-3.3.6\data\namenode</value> 
</property> 
<property> 
<name>dfs.datanode.data.dir</name> 
<value>C:\hadoop-3.3.6\data\datanode</value> 
</property> 
</configuration> 

e) Edit file C:/Hadoop-3.3.6/etc/hadoop/yarn-site.xml, paste below xml paragraph 
and save this file. 
<configuration> 
<property> 
<name>yarn.nodemanager.aux-services</name>
<value>mapreduce_shuffle</value> 
</property> 
<property> 
<name>yarn.nodemanager.auxservices.mapreduce.shuffle.class</name> 
<value>org.apache.hadoop.mapred.ShuffleHandler</value> 
</property> 
</configuration> 

f) Edit file C:/Hadoop-3.3.6/etc/hadoop/hadoop-env.cmd 
set the path for 
set JAVA_HOME=C:\java\jdk1.8.0_28\ 
 
Testing: 
Procedure to Run Hadoop 

1. Install Apache Hadoop 3.3.6 in Microsoft Windows OS 
If Apache Hadoop 3.3.6 is not already installed then follow the post Build, Install, Configure and 
Run Apache Hadoop 3.3.6 in Microsoft Windows OS. 

2. Start HDFS (Namenode and Datanode) and YARN (Resource Manager and Node Manager) 
Run following commands. Command Prompt 
C:\Users\abhijitg>cd c:\hadoop 
c:\hadoop>sbin\start-dfs 
c:\hadoop>sbin\start-yarn 
starting yarn daemons 
Start namenode and data

node with this command 
– type start-dfs.cmd 
– Start yarn through this command 
– type start-yarn.cmd 


Make sure these apps are running 
– Hadoop Namenode 
– Hadoop datanode 
– YARN Resource Manager 
– YARN Node Manager 
Namenode, Datanode, Resource Manager and Node Manager will be started in few minutes and ready 
to execute Hadoop MapReduce job in the Single Node (pseudo-distributed mode) cluster.