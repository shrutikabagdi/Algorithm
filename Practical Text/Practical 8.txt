Aim: Implement Convolution Neural Network for Deep Learning.(CNN on CIFAR-10 dataset)


Theory:

THEORY: 
An introductory look at Convolutional Neural Network with theory and code example. I want to write 
about one of the most important neural networks used in the field of deep learning, especially for image 
recognition and natural language processing: convolutional neural network, also called “CNN” or 
“ConvNet”.
 
What is Convolutional neural network? 
Convolutional neural networks. Sounds like a weird combination of biology and math with a little CS 
sprinkled in, but these networks have been some of the most influential innovations in the field of 
computer vision. 2012 was the first year that neural nets grew to prominence as Alex Krizhevsky used 
them to win that year’s ImageNet competition (basically, the annual Olympics of computer vision), 
dropping the classification error record from 26% to 15%, an astounding improvement at the time. Ever 
since then, a host of companies have been using deep learning at the core of their services. Facebook uses 
neural nets for their automatic tagging algorithms, Google for their photo search, Amazon for their 
product recommendations, Pinterest for their home feed personalization, and Instagram for their search 
infrastructure. 

Architecture of a Traditional CNN 
A convolutional neural network is composed of at least 3 layers: 
❖ Convolution layer to perform convolution operations and to generate many feature maps from one image. 
❖ A pooling layer to denoise the feature maps by shrinking non-overlapping submatricesinto summary 
statistics (such as maximums). 
❖ A dense layer which is a usual (shallow/deep) neural network that takes flattened inputs. 
 
Working of Convolutional Neural Networks. 
Convolutional neural networks are based on neuroscience findings. They are made of layers of 
artificial neurons called nodes. These nodes are functions that calculate the weighted sum of the inputs and 
return an activation map. This is the convolution part of the neural network. 

Each node in a layer is defined by its weight values. When you give a layer some data, like an image, 
it takes the pixel values and picks out some of the visual features. 
When you're working with data in a CNN, each layer returns activation maps. These maps point out 
important features in the data set. If you gave the CNN an image, it'll point out features based on pixel 
values, like colors, and give you an activation function. 

Usually with images, a CNN will initially find the edges of the picture. Then thisslight definition of 
the image will get passed to the next layer. Then that layer will start detecting things like corners and color 
groups. Then that image definition will get passed to the next layer and the cycle continues until a 
prediction is made. As the layers get more defined, this is called max pooling. It only returns the most 
relevant features from the layer in the activation map. This is what gets passed to each successive layer 
until you get the final layer. 

The last layer of a CNN is the classification layer which determines the predicted value based on the 
activation map. If you pass a handwriting sample to a CNN, the classification layer will tell you what 
letter is in the image. This is what autonomous vehicles use to determine whether an object is another car, 
a person, or some other obstacle. 

Training a CNN is similar to training many other machine learning algorithms. You'll start with some 
training data that is separate from your test data and you'll tune your weights based on the accuracy of the 
predicted values. Just be careful that you don't overfit your model. 

Different types of CNN 
❖ 1D CNN: With these, the CNN kernel moves in one direction. 1D CNNs are usually used on time-series data. 
❖ 2D CNN: These kinds of CNN kernels move in two directions. You'll see these used with image 
labelling and processing. 
❖ 3D CNN: This kind of CNN has a kernel that moves in three directions. With this type of CNN,researchers use them on 3D images like CT scans and MRIs. 






CODE:

from google.colab import drive 
drive.mount("/content/drive") 
import numpy as np 
import pandas as pd 
import tensorflow as tp 
import matplotlib.pyplot as plt 
from tensorflow.keras.datasets import cifar10 
from tensorflow.keras.models import Sequential 
from tensorflow.keras.layers import Conv2D 
from tensorflow.keras.layers import MaxPool2D 
from tensorflow.keras.layers import Flatten 
from tensorflow.keras.layers import Dropout 
from tensorflow.keras.layers import Dense 
(X_train,y_test) , (X_test,y_test) = cifar10.load_data() 
print(X_train.shape) 
print(X_test.shape) 
X_train 
plt.imshow(X_train[20]) 
plt.imshow(X_train[5]) 
for i in range(20): 
  #subplot 
  plt.subplot(5, 5, i+1) 
 
  #plotting pixel data 
  plt.imshow(X_train[i], cmap=plt.get_cmap('gray')) 
 
  #show the figure 

plt.show() 
print(X_train.shape) 
print(X_test.shape) 
X_train[0] 
X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], X_train.shape[2], 3)) 
X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], X_test.shape[2], 3)) 
print(X_train.shape) 
print(X_test.shape) 
X_train[0] 
X_train = X_train.astype('float32') / 255.0 
X_test = X_test.astype('float32') / 255.0 
X_train[0] 
model = Sequential() 
model.add(Conv2D(32, (3,3), activation='relu', input_shape=(28,28,1))) 
model.add(MaxPool2D(2,2)) 
model.add(Flatten()) 
model.add(Dense(100,activation='relu')) 
model.add(Dense(10,activation='softmax')) 
model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy']) 
(X_train, y_train), (X_test, y_test) = cifar10.load_data() 
model.fit(X_train,y_train,epochs=5) 
model.fit(X_test,y_test,epochs=5)